model:
  name: "XGBoost"
  n_estimators: 500
  max_depth: 6
  learning_rate: 0.05
  subsample: 0.8
  colsample_bytree: 0.8
  reg_alpha: 0.01
  reg_lambda: 1.0
  min_child_weight: 5
  early_stopping_rounds: 20

training:
  learning_rate: 0.05
  batch_size: 64
  max_epochs: 1  # not used directly by XGBoost, kept for config consistency
  patience: 15
